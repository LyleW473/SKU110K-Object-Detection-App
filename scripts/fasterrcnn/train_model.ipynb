{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: (The training script was used instead of the notebook, this notebook may have errors, try using the script instead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import set_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt\n",
    "%pip install clearml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all libraries/dependencies required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from torchvision import transforms as T\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor, FasterRCNN_ResNet50_FPN_Weights\n",
    "\n",
    "from src.training.fasterrcnn.dataset import CustomDataset, custom_collate_fn\n",
    "from src.training.fasterrcnn.engine import train_model_k_folds, evaluate_on_test_set\n",
    "from src.training.fasterrcnn.data import (\n",
    "                                        create_processed_dataframes, \n",
    "                                        load_annotations, \n",
    "                                        train_test_split,\n",
    "                                        create_train_val_folds,\n",
    "                                        create_train_val_dataloaders,\n",
    "                                        load_dataloader\n",
    "                                        )\n",
    "from src.training.fasterrcnn.utils import load_environment_variables, initialise_clearml_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "NUM_CLASSES = 2\n",
    "ANNOTATIONS_PATH = \"data/annotations/annotations_patches.csv\"\n",
    "IMAGE_DIR = 'data/patches_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define configuration parameters\n",
    "config_params = {\n",
    "    'USE_GPU' : True,\n",
    "    'learning-rate': 0.001,\n",
    "    'batch-size': 8, \n",
    "    'num-epochs': 100, #for actual training: 20\n",
    "    'weight-decay': 0.0005\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load annotations for patch images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df = load_annotations(ANNOTATIONS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a combined feature used for stratification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df, image_statistics = create_processed_dataframes(annotations_df=annotations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First split the data into a training set and testing set (50:50) ratio:\n",
    "- Was originally split into 80:20, but the patch dataset contains at least 11k images (with 1 patch from each image).\n",
    "- To improve training speeds, the training set has been reduced in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, train_image_names, test_image_names = train_test_split(annotations_df, image_statistics, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape, test_df.shape, annotations_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the training set into training/validation folds:\n",
    "- Data is split into 5 folds.\n",
    "- The images are split into training and validation sets based on the number of objects in each image and the mean area of all the bounding boxes for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splits = create_train_val_folds(\n",
    "                                    annotations_df=annotations_df, \n",
    "                                    image_statistics=image_statistics, \n",
    "                                    train_image_names=train_image_names\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks:\n",
    "for i in range(5):\n",
    "    print(i, all_splits[i][\"train\"].shape, all_splits[i][\"val\"].shape)\n",
    "    assert (all_splits[i][\"train\"].shape[0] + all_splits[i][\"val\"].shape[0] + test_df.shape[0]) == annotations_df.shape[0], \"Data processing incorrect, missing objects.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define image transforms (data augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = T.Compose([T.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the device available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model \n",
    "model = fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, NUM_CLASSES)\n",
    "\n",
    "# Move the model to the device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the environment variables required to run training with ClearML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_environment_variables(env_path=\"./.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this in terminal: clearml-init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload patches dataset zip using following terminal commands (deprecated):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearml-data create --project \"Object Detection Project\" --name \"Patches Dataset\"\n",
    "\n",
    "# clearml-data add --files \"data/patches_dataset.zip\"\n",
    "\n",
    "# clearml-data upload\n",
    "\n",
    "# after the above command run successfully, run: clearml-data close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise ClearML task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = initialise_clearml_task(configuration_params=config_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For remote execution: load dataset we uploaded from clearml (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = ClearMLDataset.get(dataset_project=\"Object Detection Project\", dataset_name=\"Patches Dataset\")\n",
    "# dataset_path = dataset.get_local_copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = task.name+'_'+task.id+'/'\n",
    "os.makedirs(prefix, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the dataloaders:\n",
    "- 'dataloaders_train' will contain all of the data loaders for the training folds.\n",
    "- 'dataloaders_val' will contain all of the data loaders for the validation folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataloaders\n",
    "dataloaders_train, dataloaders_val = create_train_val_dataloaders(\n",
    "                                                                all_splits=all_splits, \n",
    "                                                                image_dir=IMAGE_DIR, \n",
    "                                                                image_transforms=image_transforms, \n",
    "                                                                config_params=config_params,\n",
    "                                                                collate_fn=custom_collate_fn,\n",
    "                                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating test dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_df, IMAGE_DIR, transforms=image_transforms)\n",
    "test_dl = load_dataloader(\n",
    "                        dataset=test_dataset, \n",
    "                        config_params=config_params,\n",
    "                        collate_fn=custom_collate_fn,\n",
    "                        shuffle=False # Do not shuffle the test set\n",
    "                        )\n",
    "\n",
    "\n",
    "# TEMP: Print the first 5 batches of the test loader#\n",
    "print(\"num batches in dataloader\", len(test_dl))\n",
    "for i, (images, targets) in enumerate(test_dl):\n",
    "    print(f\"Batch {i}: {len(images)} images, {len(targets)} targets\")\n",
    "    print(targets)\n",
    "    print(i)\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the first 5 images along with its bounding boxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i, (images, targets) in enumerate(dataloaders_train['fold_1_train']):\n",
    "    print(f\"Batch {i}: {len(images)} images, {len(targets)} targets\")\n",
    "    print(targets)\n",
    "    print(i)\n",
    "    \n",
    "    # Convert the tensor image to a numpy array and then to a PIL Image\n",
    "    image_np = (images[0].numpy() * 255).astype(np.uint8).transpose(1, 2, 0)\n",
    "    \n",
    "    # Visualize the image with targets\n",
    "    bboxes = targets[0][\"boxes\"].numpy().astype(int)\n",
    "    print(bboxes.shape)\n",
    "\n",
    "    image_copy = image_np.copy()\n",
    "\n",
    "    for bbox in bboxes:\n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "        image_copy = cv2.rectangle(image_copy, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "\n",
    "    plt.imshow(image_copy)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, best_fold_model_path = train_model_k_folds(\n",
    "                                                    model=model, \n",
    "                                                    train_dataloaders=dataloaders_train,\n",
    "                                                    val_dataloaders=dataloaders_val,\n",
    "                                                    device=device, \n",
    "                                                    config_params=config_params,\n",
    "                                                    prefix=prefix\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate 'best' model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "final_model = copy.deepcopy(best_model)\n",
    "final_model.load_state_dict(torch.load(best_fold_model_path, weights_only=True)) # Adjust this path if you want to load the overall best fold\n",
    "\n",
    "# Call the test function to evaluate on the test set\n",
    "test_results = evaluate_on_test_set(final_model, test_dl, device)\n",
    "\n",
    "# Log the test results (e.g., mAP, Precision, Recall) to ClearML\n",
    "task.upload_artifact(name=\"Test Results\", artifact_object=test_results)\n",
    "\n",
    "task.close() # uncomment to close the task"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
